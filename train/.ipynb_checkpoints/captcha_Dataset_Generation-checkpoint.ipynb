{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/joel/Desktop/captcha-breaker/captcha', '/home/joel/Desktop/captcha-breaker/captcha/captcha', '', '/home/joel/anaconda2/envs/ml/lib/python36.zip', '/home/joel/anaconda2/envs/ml/lib/python3.6', '/home/joel/anaconda2/envs/ml/lib/python3.6/lib-dynload', '/home/joel/.local/lib/python3.6/site-packages', '/home/joel/anaconda2/envs/ml/lib/python3.6/site-packages', '/home/joel/anaconda2/envs/ml/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg', '/home/joel/anaconda2/envs/ml/lib/python3.6/site-packages/instagram_scraper-1.5.40-py3.6.egg', '/home/joel/anaconda2/envs/ml/lib/python3.6/site-packages/IPython/extensions', '/home/joel/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/joel/Desktop/captcha-breaker/captcha') # use modified library\n",
    "print(sys.path)\n",
    "\n",
    "from captcha.image import ImageCaptcha\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702p [[3, 15, 28, 60], [47, 15, 72, 60], [71, 7, 105, 68], [125, 11, 155, 64], [150, 5, 180, 70]]\n",
      "kW4wU4 [[2, 11, 24, 64], [41, 7, 66, 67], [75, 11, 97, 64], [94, 11, 118, 64], [115, 15, 133, 60], [149, 7, 174, 67]]\n",
      "370nUkE [[2, 11, 32, 64], [31, 7, 65, 67], [59, 15, 84, 60], [84, 15, 109, 60], [105, 15, 130, 60], [127, 15, 152, 60], [151, 11, 181, 64]]\n",
      "QE0DUw [[3, 1, 25, 73], [40, 11, 59, 64], [72, 15, 88, 60], [98, 7, 120, 67], [135, 15, 151, 60], [148, 11, 169, 64]]\n",
      "7Qjoquu [[2, 15, 19, 60], [15, 6, 35, 69], [34, 1, 57, 74], [67, 15, 84, 60], [79, 1, 102, 74], [112, 11, 132, 64], [152, 11, 172, 64]]\n",
      "PCRBI [[3, 15, 28, 60], [19, 15, 44, 60], [67, 15, 92, 60], [108, 7, 142, 67], [141, 7, 175, 67]]\n",
      "D1pUX35 [[15, 15, 31, 60], [45, 7, 66, 67], [80, 1, 101, 74], [111, 11, 129, 64], [126, 11, 145, 64], [142, 15, 157, 60], [153, 15, 168, 60]]\n",
      "EH2uDu [[13, 7, 37, 67], [36, 15, 54, 60], [54, 7, 79, 67], [93, 15, 112, 60], [112, 7, 136, 67], [156, 7, 181, 68]]\n",
      "dferh [[3, 15, 26, 60], [41, 11, 69, 64], [80, 11, 108, 64], [103, 15, 126, 60], [147, 11, 174, 64]]\n",
      "ZoZoA [[23, 7, 50, 67], [61, 7, 88, 68], [88, 7, 115, 67], [109, 7, 136, 68], [152, 15, 172, 60]]\n"
     ]
    }
   ],
   "source": [
    "# Define an alphanumeric character set\n",
    "characters = string.digits + string.ascii_uppercase + string.ascii_lowercase\n",
    "\n",
    "width, height, n_class = 200, 75, len(characters)\n",
    "\n",
    "generator = ImageCaptcha(width=width, height=height)\n",
    "\n",
    "num_samples = 10\n",
    "split = .8\n",
    "split_index = int(.8 * num_samples) - 1\n",
    "\n",
    "f = open(\"../data/annotations/bboxes.txt\",\"w+\")\n",
    "\n",
    "for i in np.arange(0, num_samples):\n",
    "    n_len = random.randint(4,7)\n",
    "    random_str = ''.join([random.choice(characters) for j in range(n_len)])\n",
    "    img, boxes = generator.generate_image(random_str, bbox=True)\n",
    "    filename = str(i) + '_' + random_str + '.png'\n",
    "    print(random_str, boxes)\n",
    "    if i <= split_index:\n",
    "        img.save('../data/captcha/train/' + filename, 'png')\n",
    "        f.write('train/' + filename + ' ' + str(boxes) + '\\n')\n",
    "    else:\n",
    "        img.save('../data/captcha/test/' + filename, 'png')\n",
    "        f.write('test/' + filename + ' ' + str(boxes) + '\\n')\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Lambda, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaBreaker:\n",
    "    \n",
    "    def __init__(self, input_width, input_height, num_classes, activation):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.num_classes = num_classes\n",
    "        self.activation = activation\n",
    "    \n",
    "    @staticmethod\n",
    "    def build():\n",
    "        # initialize the input shape and channel dimension (this code\n",
    "        # assumes you are using TensorFlow which utilizes channels\n",
    "        # last ordering)\n",
    "        input_shape = (self.input_height, self.input_width, 3)\n",
    "        channel_dim = -1\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "        \n",
    "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
    "\n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=channel_dim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=channel_dim)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=channel_dim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=channel_dim)(x)\n",
    "        x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=channel_dim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(self.num_classes)(x)\n",
    "        x = Activation(self.activation, name=\"output\")(x)\n",
    "\n",
    "        # create the model\n",
    "        model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs=x,\n",
    "            name=\"captcha_breaker\")\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CaptchaBreaker(200, 75, len(characters)).build()\n",
    "logging = TensorBoard(log_dir='logs')\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../data/captcha/train',\n",
    "    target_size=(200, 75),\n",
    "    batch_size=32)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "    # use custom yolo_loss Lambda layer.\n",
    "    'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "batch_size = 32\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=50,\n",
    "        initial_epoch=0,\n",
    "        callbacks=[logging, checkpoint])\n",
    "model.save_weights(log_dir + 'trained_weights_stage_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
